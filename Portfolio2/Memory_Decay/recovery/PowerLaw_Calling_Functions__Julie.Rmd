---
title: "Calling_Functions_Markdown"
author: "Lasse Hyldig Hansen"
date: "2023-02-21"
output: html_document
---

## Loading Packages


```{r}
library(tidyverse)
library(LaplacesDemon)
p_load(tidyverse, rstan)
```

## Loading matching pennies game function

```{r}
source("Matching_Pennies_Game_Function.R")

```

# Playing games with different agents

## Power law memory vs Random Agent & WSLS

```{r}

source("Matching_Pennies_Game_Function.R")

source("LTMAgent_Function.R")


# Testing the LTMAgent on a hardcoded input
results = LTMAgent_Function(c(1,0,1,1,0), alpha, beta, power)

alpha <- 0
bias <- 0.7 # Random agent's bias
beta <- 0.5
power = 0.5 # This one can very easily get too high, causing the agent to weigh recent memories far too much.
n_trials = 120
n_agents = 100
noise = 0.1
PL_VS_RANDOM_DF = Matching_Pennies_Game(n_agents, 
                                       n_trials, 
                                       function_give = "RandomAgentNoise_Function", 
                                       alpha,
                                       beta,       
                                       noise,
                                       power)

sum(PL_VS_RANDOM_DF$agent_take_payoff_m[1:120])


PL_VS_WSLS = Matching_Pennies_Game(n_agents, 
                                       n_trials, 
                                       function_give = "WSLSAgent_Function", 
                                       alpha,
                                       beta,       
                                       noise,
                                       power)

sum(PL_VS_WSLS$agent_take_payoff_m) # It performs poorly - but not ridiculously so. It's lagging behind.

```


```{r simple parameter recovery}
pacman::p_load(pacman)

p_load(cmdstanr)

file <- file.path("long-term-model.stan")

mod <- cmdstan_model(file,
                     cpp_options= list(stan_threads= TRUE),stanc_options= list("O1"))

# Fitting model


data <- list(N = 119, choice = PL_VS_RANDOM_DF$agent_take_choices[2:120], others_choice = PL_VS_RANDOM_DF$agent_give_choices[1:119], power = power)


samples <- mod$sample(
  data = data,
  seed = 1000,
  chains = 1,
  parallel_chains = 1,
  threads_per_chain = 1,
  iter_warmup = 1000,
  iter_sampling = 2000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99,)
  
  
p_load(posterior)

draws_df <- as_draws_df(samples$draws())

    
samples$summary()
  

```

```{r}
# Now let's plot the density for alpha (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(alpha), fill = "blue", alpha = 0.3) +
  geom_density(aes(alpha_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0, size = 2) +
  xlab("Alpha") +
  ylab("Posterior Density") +
  theme_classic()
```

```{r}
# Now let's plot the density for beta (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(beta), fill = "blue", alpha = 0.3) +
  geom_density(aes(beta_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0, size = 2) +
  xlab("Beta") +
  ylab("Posterior Density") +
  theme_classic()
```

```{r}
ggplot(draws_df) +
  geom_histogram(aes(`prior_preds5`), color = "yellow", fill = "lightyellow", alpha = 0.2) +
  geom_histogram(aes(`prior_preds7`), color = "green", fill = "lightgreen", alpha = 0.2) +
  geom_histogram(aes(`prior_preds9`), color = "blue", fill = "lightblue", alpha = 0.2) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()


```

### Prior sensitivity check for the memory model
```{r}

prior_mean_alpha <- 0
prior_sd_alpha <- seq(0.1, 0.5, 0.1)
prior_mean_beta <- 0
prior_sd_beta <- seq(0.1, 0.5, 0.1)
priors <-  tibble(expand.grid(tibble(prior_mean_alpha, prior_sd_alpha, prior_mean_beta, prior_sd_beta)))
```

```{r}
file <- file.path("prior_sensitivity_LTM.stan")

mod <- cmdstan_model(file,
                     cpp_options= list(stan_threads= TRUE),stanc_options= list("O1"))

# Fitting model

pacman::p_load(future, purrr, furrr)
plan(multisession, workers = 4)


sim_d_and_fit <- function(prior_mean_alpha, prior_sd_alpha, prior_mean_beta, prior_sd_beta) {
  
    data <- list(
        N = 119, 
        choice = PL_VS_RANDOM_DF$agent_take_choices[2:120], 
        others_choice = PL_VS_RANDOM_DF$agent_give_choices[1:119], 
        power = power,
        prior_mean_alpha = prior_mean_alpha,
        prior_sd_alpha = prior_sd_alpha,
        prior_mean_beta = prior_mean_beta,
        prior_sd_beta = prior_sd_beta
      )
    
    samples <- mod$sample(
      data = data,
      seed = 1000,
      chains = 1,
      parallel_chains = 1,
      threads_per_chain = 1,
      iter_warmup = 1000,
      iter_sampling = 2000,
      refresh = 0,
      max_treedepth = 20,
      adapt_delta = 0.99,
    )
    
    draws_df <- as_draws_df(samples$draws()) 
      temp <- tibble(alpha_prior = draws_df$alpha_prior, 
                     beta_prior = draws_df$beta_prior, 
                     alpha_posterior = draws_df$alpha, 
                     beta_posterior = draws_df$beta, 
                     prior_preds5 = draws_df$prior_preds5, 
                     prior_preds7 = draws_df$prior_preds7, 
                     prior_preds9 = draws_df$prior_preds9, 
                     posterior_preds5 = draws_df$post_preds5,
                     posterior_preds7 = draws_df$post_preds7,
                     posterior_preds9 = draws_df$post_preds9, 
                     prior_mean_alpha = prior_mean_alpha,
                     prior_sd_alpha = prior_sd_alpha, 
                     prior_mean_beta = prior_mean_beta,
                     prior_sd_beta = prior_sd_beta)
    
    return(temp)
  
}



recovery_df <- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE))

write_csv(recovery_df, "W4_MemoryPriorSensitivity.csv")


```


```{r}
recovery_df <- read_csv("W4_MemoryPriorSensitivity.csv")
```

```{r}
ggplot(recovery_df, aes(prior_sd_beta, beta_posterior)) +
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = 0.3, color = "red") +
  geom_smooth(method = lm) +
  facet_wrap(.~prior_sd_alpha) +
  theme_classic()
```


# Goals: